{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Data: `Dataset`, `DataLoader`, `Sampler`, and `Transforms`\n",
    "\n",
    "These basic concepts make it easy to work with large data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init, helpers, utils, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-27T14:31:35.980115Z",
     "iopub.status.busy": "2020-11-27T14:31:35.979655Z",
     "iopub.status.idle": "2020-11-27T14:31:36.183761Z",
     "shell.execute_reply": "2020-11-27T14:31:36.183398Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-27T14:31:36.188158Z",
     "iopub.status.busy": "2020-11-27T14:31:36.186746Z",
     "iopub.status.idle": "2020-11-27T14:31:36.451856Z",
     "shell.execute_reply": "2020-11-27T14:31:36.452141Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-27T14:31:36.454854Z",
     "iopub.status.busy": "2020-11-27T14:31:36.454516Z",
     "iopub.status.idle": "2020-11-27T14:31:36.456675Z",
     "shell.execute_reply": "2020-11-27T14:31:36.456352Z"
    }
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.core.debugger import set_trace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "It's easy to create your `Dataset`,\n",
    "but PyTorch comes with some\n",
    "[build-in datasets](https://pytorch.org/docs/stable/torchvision/datasets.html):\n",
    "\n",
    "- MNIST\n",
    "- Fashion-MNIST\n",
    "- KMNIST\n",
    "- EMNIST\n",
    "- FakeData\n",
    "- COCO\n",
    "  - Captions\n",
    "  - Detection\n",
    "- LSUN\n",
    "- ImageFolder\n",
    "- DatasetFolder\n",
    "- Imagenet-12\n",
    "- CIFAR\n",
    "- STL10\n",
    "- SVHN\n",
    "- PhotoTour\n",
    "- SBU\n",
    "- Flickr\n",
    "- VOC\n",
    "- Cityscapes\n",
    "\n",
    "`Dataset` gives you information about the number of samples (implement `__len__`) and gives you the sample at a given index (implement `__getitem__`.\n",
    "It's a nice and simple abstraction to work with data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-27T14:31:36.459242Z",
     "iopub.status.busy": "2020-11-27T14:31:36.458823Z",
     "iopub.status.idle": "2020-11-27T14:31:36.460993Z",
     "shell.execute_reply": "2020-11-27T14:31:36.460694Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "class Dataset(object):\n",
    "    def __getitem__(self, index):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def __len__(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def __add__(self, other):\n",
    "        return ConcatDataset([self, other])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `ImageFolder` dataset is quite useful and follows the usual conventions for folder layouts:\n",
    "\n",
    "```\n",
    "root/dog/xxx.png\n",
    "root/dog/xxy.png\n",
    "root/dog/xxz.png\n",
    "\n",
    "root/cat/123.png\n",
    "root/cat/nsdf3.png\n",
    "root/cat/asd932_.png\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: dogs and cats dataset\n",
    "https://www.kaggle.com/chetankv/dogs-cats-images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-27T14:31:36.464046Z",
     "iopub.status.busy": "2020-11-27T14:31:36.463671Z",
     "iopub.status.idle": "2020-11-27T14:31:36.623833Z",
     "shell.execute_reply": "2020-11-27T14:31:36.622645Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Too many parameters - dogscats/\n"
     ]
    }
   ],
   "source": [
    "!tree -d dogscats/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-27T14:31:36.635307Z",
     "iopub.status.busy": "2020-11-27T14:31:36.633363Z",
     "iopub.status.idle": "2020-11-27T14:31:36.664165Z",
     "shell.execute_reply": "2020-11-27T14:31:36.663720Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'dogscats/training_set/'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-e541651848b4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfolder\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImageFolder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtrain_ds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImageFolder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"dogscats/training_set/\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\python\\python39\\lib\\site-packages\\torchvision\\datasets\\folder.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, root, transform, target_transform, loader, is_valid_file)\u001b[0m\n\u001b[0;32m    308\u001b[0m             \u001b[0mis_valid_file\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m     ):\n\u001b[1;32m--> 310\u001b[1;33m         super(ImageFolder, self).__init__(root, loader, IMG_EXTENSIONS if is_valid_file is None else None,\n\u001b[0m\u001b[0;32m    311\u001b[0m                                           \u001b[0mtransform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    312\u001b[0m                                           \u001b[0mtarget_transform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\python39\\lib\\site-packages\\torchvision\\datasets\\folder.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)\u001b[0m\n\u001b[0;32m    143\u001b[0m         super(DatasetFolder, self).__init__(root, transform=transform,\n\u001b[0;32m    144\u001b[0m                                             target_transform=target_transform)\n\u001b[1;32m--> 145\u001b[1;33m         \u001b[0mclasses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_classes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    146\u001b[0m         \u001b[0msamples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_valid_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\python39\\lib\\site-packages\\torchvision\\datasets\\folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[1;34m(self, directory)\u001b[0m\n\u001b[0;32m    219\u001b[0m             \u001b[1;33m(\u001b[0m\u001b[0mTuple\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mList\u001b[0m \u001b[0mof\u001b[0m \u001b[0mall\u001b[0m \u001b[0mclasses\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mdictionary\u001b[0m \u001b[0mmapping\u001b[0m \u001b[0meach\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mto\u001b[0m \u001b[0man\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m         \"\"\"\n\u001b[1;32m--> 221\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfind_classes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\python39\\lib\\site-packages\\torchvision\\datasets\\folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[1;34m(directory)\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[0mSee\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;32mclass\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDatasetFolder\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdetails\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \"\"\"\n\u001b[1;32m---> 40\u001b[1;33m     \u001b[0mclasses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mentry\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscandir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mentry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Couldn't find any class folder in {directory}.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'dogscats/training_set/'"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets.folder import ImageFolder\n",
    "\n",
    "train_ds = ImageFolder(\"dogscats/training_set/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-27T14:31:36.667927Z",
     "iopub.status.busy": "2020-11-27T14:31:36.667421Z",
     "iopub.status.idle": "2020-11-27T14:31:36.670222Z",
     "shell.execute_reply": "2020-11-27T14:31:36.669810Z"
    }
   },
   "outputs": [],
   "source": [
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-27T14:31:36.672927Z",
     "iopub.status.busy": "2020-11-27T14:31:36.672301Z",
     "iopub.status.idle": "2020-11-27T14:31:36.675198Z",
     "shell.execute_reply": "2020-11-27T14:31:36.674769Z"
    }
   },
   "outputs": [],
   "source": [
    "# the __len__ method\n",
    "len(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-27T14:31:36.678250Z",
     "iopub.status.busy": "2020-11-27T14:31:36.677891Z",
     "iopub.status.idle": "2020-11-27T14:31:36.684359Z",
     "shell.execute_reply": "2020-11-27T14:31:36.684018Z"
    }
   },
   "outputs": [],
   "source": [
    "# the __getitem__ method\n",
    "train_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-27T14:31:36.686858Z",
     "iopub.status.busy": "2020-11-27T14:31:36.686527Z",
     "iopub.status.idle": "2020-11-27T14:31:36.711810Z",
     "shell.execute_reply": "2020-11-27T14:31:36.712137Z"
    }
   },
   "outputs": [],
   "source": [
    "train_ds[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-27T14:31:36.714941Z",
     "iopub.status.busy": "2020-11-27T14:31:36.714576Z",
     "iopub.status.idle": "2020-11-27T14:31:36.717516Z",
     "shell.execute_reply": "2020-11-27T14:31:36.717155Z"
    }
   },
   "outputs": [],
   "source": [
    "train_ds[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optionally, some datasets offer convenience functions and attributes.\n",
    "This is not enforced by the interface! Don't rely on it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-27T14:31:36.720255Z",
     "iopub.status.busy": "2020-11-27T14:31:36.719850Z",
     "iopub.status.idle": "2020-11-27T14:31:36.721993Z",
     "shell.execute_reply": "2020-11-27T14:31:36.722311Z"
    }
   },
   "outputs": [],
   "source": [
    "train_ds.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-27T14:31:36.725112Z",
     "iopub.status.busy": "2020-11-27T14:31:36.724709Z",
     "iopub.status.idle": "2020-11-27T14:31:36.726896Z",
     "shell.execute_reply": "2020-11-27T14:31:36.727241Z"
    }
   },
   "outputs": [],
   "source": [
    "train_ds.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-27T14:31:36.753922Z",
     "iopub.status.busy": "2020-11-27T14:31:36.753563Z",
     "iopub.status.idle": "2020-11-27T14:31:36.757108Z",
     "shell.execute_reply": "2020-11-27T14:31:36.756785Z"
    }
   },
   "outputs": [],
   "source": [
    "train_ds.imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-27T14:31:36.760166Z",
     "iopub.status.busy": "2020-11-27T14:31:36.759865Z",
     "iopub.status.idle": "2020-11-27T14:31:36.957782Z",
     "shell.execute_reply": "2020-11-27T14:31:36.958024Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "rand_idx = np.random.randint(0, len(train_ds), 4)\n",
    "for i in rand_idx:\n",
    "    img, label_id = train_ds[i]\n",
    "    print(label_id, train_ds.classes[label_id], i)\n",
    "    display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `torchvision.transforms`\n",
    "\n",
    "Common image transformation that can be composed/chained [[docs]](https://pytorch.org/docs/stable/torchvision/transforms.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-27T14:31:36.960645Z",
     "iopub.status.busy": "2020-11-27T14:31:36.960334Z",
     "iopub.status.idle": "2020-11-27T14:31:36.962821Z",
     "shell.execute_reply": "2020-11-27T14:31:36.962385Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-27T14:31:36.966499Z",
     "iopub.status.busy": "2020-11-27T14:31:36.966183Z",
     "iopub.status.idle": "2020-11-27T14:31:36.977135Z",
     "shell.execute_reply": "2020-11-27T14:31:36.977548Z"
    }
   },
   "outputs": [],
   "source": [
    "_image_size = 224\n",
    "_mean = [0.485, 0.456, 0.406]\n",
    "_std = [0.229, 0.224, 0.225]\n",
    "\n",
    "\n",
    "trans = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.RandomCrop(_image_size),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(.3, .3, .3),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(_mean, _std),\n",
    "])\n",
    "\n",
    "trans(train_ds[7074][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `torchvision.transforms.functional`\n",
    "\n",
    ">Functional transforms give you fine-grained control of the transformation pipeline. As opposed to the transformations above, functional transforms don’t contain a random number generator for their parameters. That means you have to specify/generate all parameters, but you can reuse the functional transform. For example, you can apply a functional transform to multiple images like this:\n",
    ">\n",
    "> https://pytorch.org/docs/stable/torchvision/transforms.html#functional-transforms\n",
    "\n",
    "```python\n",
    "import torchvision.transforms.functional as TF\n",
    "import random\n",
    "\n",
    "def my_segmentation_transforms(image, segmentation):\n",
    "    if random.random() > 5:\n",
    "        angle = random.randint(-30, 30)\n",
    "        image = TF.rotate(image, angle)\n",
    "        segmentation = TF.rotate(segmentation, angle)\n",
    "    # more transforms ...\n",
    "    return image, segmentation\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ref:\n",
    "- https://pytorch.org/docs/stable/torchvision/transforms.htm\n",
    "- https://pytorch.org/docs/stable/torchvision/transforms.html#functional-transforms\n",
    "- https://pytorch.org/tutorials/beginner/data_loading_tutorial.html\n",
    "- https://github.com/mdbloice/Augmentor\n",
    "- https://github.com/aleju/imgaug\n",
    "\n",
    "Shout-out:\n",
    "- Hig performance image augmentation with pillow-simd [[github]](https://github.com/uploadcare/pillow-simd) [[benchmark]](http://python-pillow.org/pillow-perf/)\n",
    "- Improving Deep Learning Performance with AutoAugment [[blog]](https://ai.googleblog.com/2018/06/improving-deep-learning-performance.html) [[paper]](https://arxiv.org/abs/1805.09501) [[pytorch implementation]](https://github.com/DeepVoltaire/AutoAugment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader\n",
    "The `DataLoader` class offers batch loading of datasets with multi-processing and different sample strategies [[docs]](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader).\n",
    "\n",
    "The signature looks something like this:\n",
    "```python\n",
    "DataLoader(\n",
    "    dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    sampler=None,\n",
    "    batch_sampler=None,\n",
    "    num_workers=0,\n",
    "    collate_fn=default_collate,\n",
    "    pin_memory=False,\n",
    "    drop_last=False,\n",
    "    timeout=0,\n",
    "    worker_init_fn=None\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-27T14:31:36.981236Z",
     "iopub.status.busy": "2020-11-27T14:31:36.980681Z",
     "iopub.status.idle": "2020-11-27T14:31:36.983306Z",
     "shell.execute_reply": "2020-11-27T14:31:36.982874Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-27T14:31:36.986689Z",
     "iopub.status.busy": "2020-11-27T14:31:36.986225Z",
     "iopub.status.idle": "2020-11-27T14:31:37.007950Z",
     "shell.execute_reply": "2020-11-27T14:31:37.008251Z"
    }
   },
   "outputs": [],
   "source": [
    "train_ds = ImageFolder(\"dogscats/training_set/\", transform=trans)\n",
    "train_dl = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=2,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-27T14:31:37.010948Z",
     "iopub.status.busy": "2020-11-27T14:31:37.010492Z",
     "iopub.status.idle": "2020-11-27T14:31:37.047111Z",
     "shell.execute_reply": "2020-11-27T14:31:37.046421Z"
    }
   },
   "outputs": [],
   "source": [
    "train_iter = iter(train_dl)\n",
    "X, y = next(train_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-27T14:31:37.052074Z",
     "iopub.status.busy": "2020-11-27T14:31:37.051322Z",
     "iopub.status.idle": "2020-11-27T14:31:37.054409Z",
     "shell.execute_reply": "2020-11-27T14:31:37.053801Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"X:\", X.shape)\n",
    "print(\"y:\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that I passed `trans`, which returns `torch.Tensor`, not pillow images.\n",
    "DataLoader expects tensors, numbers, dicts or lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-27T14:31:37.057933Z",
     "iopub.status.busy": "2020-11-27T14:31:37.057369Z",
     "iopub.status.idle": "2020-11-27T14:31:37.064720Z",
     "shell.execute_reply": "2020-11-27T14:31:37.064374Z"
    }
   },
   "outputs": [],
   "source": [
    "_train_ds = ImageFolder(\"dogscats/test_set/\", transform=trans) \n",
    "_train_dl = DataLoader(_train_ds, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `collate_fn`\n",
    "The `collate_fn` argument of `DataLoader` allows you to customize how single datapoints are put together into a batch.\n",
    "`collate_fn` is a simple callable that gets a list of datapoints (i.e. what `dataset.__getitem__` returns)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of a custom `collate_fn`\n",
    "(taken from [here](https://discuss.pytorch.org/t/how-to-create-a-dataloader-with-variable-size-input/8278/3)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-27T14:31:37.067633Z",
     "iopub.status.busy": "2020-11-27T14:31:37.067320Z",
     "iopub.status.idle": "2020-11-27T14:31:37.069290Z",
     "shell.execute_reply": "2020-11-27T14:31:37.068918Z"
    }
   },
   "outputs": [],
   "source": [
    "def my_collate_fn(list_of_x_y):\n",
    "    data = [item[0] for item in list_of_x_y]\n",
    "    target = [item[1] for item in list_of_x_y]\n",
    "    target = torch.LongTensor(target)\n",
    "    return [data, target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampler\n",
    "`Sampler` define **how** to sample from the dataset [[docs]](https://pytorch.org/docs/stable/data.html#torch.utils.data.sampler.Sampler).\n",
    "\n",
    "Examples:\n",
    "- `SequentialSampler`\n",
    "- `RandomSamples`\n",
    "- `SubsetSampler`\n",
    "- `WeightedRandomSampler`\n",
    "\n",
    "Write your own by simply implementing `__iter__` to iterate over the indices of the dataset.\n",
    "\n",
    "```python\n",
    "class Sampler(object):\n",
    "    def __init__(self, data_source):\n",
    "        pass\n",
    "\n",
    "    def __iter__(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def __len__(self):\n",
    "        raise NotImplementedError\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recap\n",
    "- `Dataset`: get one datapoint\n",
    "- `transforms`: composable transformations\n",
    "- `DataLoader`: combine single datapoints into batches (plus multi processing and more)\n",
    "- `Sampler`: **how** to sample from a dataset\n",
    "\n",
    "**Simple but extensible interfaces**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "Go out and play:\n",
    "\n",
    "- Maybe extend the `DogsCatsDataset` such that you can specify the size of dataset, i.e. the number of samples.\n",
    "- Maybe try the `Subset` [[docs]](https://pytorch.org/docs/stable/data.html#torch.utils.data.Subset) to create smaller datasets.\n",
    "- Maybe create `SubsetFraction` where you can specify the size of the dataset (between 0. and 1.).\n",
    "- Maybe write a custom collate function for the `DogsCatsDataset` that turns it into a dataset appropriate to use in an autoencoder settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-27T14:31:37.071803Z",
     "iopub.status.busy": "2020-11-27T14:31:37.071438Z",
     "iopub.status.idle": "2020-11-27T14:31:37.073337Z",
     "shell.execute_reply": "2020-11-27T14:31:37.072968Z"
    }
   },
   "outputs": [],
   "source": [
    "def autoencoder_collate_fn(list_of_x_y):\n",
    "    # TODO implement me\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-27T14:31:37.076254Z",
     "iopub.status.busy": "2020-11-27T14:31:37.075891Z",
     "iopub.status.idle": "2020-11-27T14:31:37.077845Z",
     "shell.execute_reply": "2020-11-27T14:31:37.077474Z"
    }
   },
   "outputs": [],
   "source": [
    "class MyDataSet(Dataset):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # TODO implement me\n",
    "    \n",
    "    def __len__(self):\n",
    "        # TODO implement me\n",
    "        pass\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # TODO implement me\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
